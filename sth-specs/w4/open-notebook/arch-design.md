# Open Notebook æ¶æ„è®¾è®¡åˆ†ææ–‡æ¡£

> **é¡¹ç›®**: Open Notebook - å¼€æº AI ç ”ç©¶åŠ©æ‰‹
> **ç‰ˆæœ¬**: v1.2.4+
> **åˆ†ææ—¥æœŸ**: 2026-01-10
> **ä½œè€…**: æ¶æ„åˆ†æ

---

## ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
2. [æŠ€æœ¯æ ˆ](#2-æŠ€æœ¯æ ˆ)
3. [æ•´ä½“æ¶æ„](#3-æ•´ä½“æ¶æ„)
4. [æ ¸å¿ƒæ¨¡å—è¯¦è§£](#4-æ ¸å¿ƒæ¨¡å—è¯¦è§£)
5. [æ•°æ®æµåˆ†æ](#5-æ•°æ®æµåˆ†æ)
6. [æ¶æ„æ¨¡å¼](#6-æ¶æ„æ¨¡å¼)
7. [å…³é”®è®¾è®¡å†³ç­–](#7-å…³é”®è®¾è®¡å†³ç­–)
8. [æ‰©å±•æ€§åˆ†æ](#8-æ‰©å±•æ€§åˆ†æ)
9. [å®‰å…¨æ€§è€ƒè™‘](#9-å®‰å…¨æ€§è€ƒè™‘)
10. [æ€§èƒ½ä¼˜åŒ–](#10-æ€§èƒ½ä¼˜åŒ–)
11. [éƒ¨ç½²æ¶æ„](#11-éƒ¨ç½²æ¶æ„)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®å®šä½

**Open Notebook** æ˜¯ä¸€ä¸ªå¼€æºã€éšç§ä¼˜å…ˆçš„ Google Notebook LM æ›¿ä»£æ–¹æ¡ˆã€‚å®ƒæ˜¯ä¸€ä¸ª AI é©±åŠ¨çš„ç ”ç©¶åŠ©æ‰‹ï¼Œæ”¯æŒï¼š

- ğŸ“š **å¤šæ¨¡æ€å†…å®¹ç®¡ç†**ï¼šPDFã€éŸ³é¢‘ã€è§†é¢‘ã€ç½‘é¡µç­‰
- ğŸ¤– **å¤š AI æä¾›å•†æ”¯æŒ**ï¼š16+ æä¾›å•†ï¼ˆOpenAIã€Anthropicã€Ollama ç­‰ï¼‰
- ğŸ™ï¸ **ä¸“ä¸šæ’­å®¢ç”Ÿæˆ**ï¼šå¤šè¯´è¯äººæ’­å®¢ç”Ÿæˆ
- ğŸ” **æ™ºèƒ½æœç´¢**ï¼šå…¨æ–‡æœç´¢å’Œå‘é‡è¯­ä¹‰æœç´¢
- ğŸ’¬ **ä¸Šä¸‹æ–‡å¯¹è¯**ï¼šåŸºäºç ”ç©¶å†…å®¹çš„ AI å¯¹è¯
- ğŸ”’ **å®Œå…¨æœ¬åœ°åŒ–**ï¼šè‡ªæ‰˜ç®¡é€‰é¡¹ï¼Œæ•°æ®å®Œå…¨æŒæ§

### 1.2 æ ¸å¿ƒä»·å€¼

- **éšç§ä¼˜å…ˆ**ï¼šç ”ç©¶æ•°æ®å®Œå…¨ç§æœ‰å’Œå®‰å…¨
- **ä¾›åº”å•†æ— å…³**ï¼šæ”¯æŒå¤šç§ AI æä¾›å•†ï¼Œæ— ä¾›åº”å•†é”å®š
- **æˆæœ¬å¯æ§**ï¼šé€‰æ‹©æ›´ä¾¿å®œçš„ AI æä¾›å•†æˆ–æœ¬åœ°è¿è¡Œ
- **å®Œå…¨å¯å®šåˆ¶**ï¼šå¼€æºæ¶æ„ï¼Œæ— é™æ‰©å±•æ€§

### 1.3 æŠ€æœ¯äº®ç‚¹

- âœ… **å¼‚æ­¥ä¼˜å…ˆè®¾è®¡**ï¼šå…¨æ ˆå¼‚æ­¥å¤„ç†
- âœ… **å›¾æ•°æ®åº“**ï¼šSurrealDB æ”¯æŒå…³ç³»å’Œå‘é‡æœç´¢
- âœ… **å·¥ä½œæµç¼–æ’**ï¼šLangGraph çŠ¶æ€æœº
- âœ… **å¤šæä¾›å•†æŠ½è±¡**ï¼šEsperanto ç»Ÿä¸€æ¥å£
- âœ… **è‡ªåŠ¨è¿ç§»**ï¼šæ•°æ®åº“æ¶æ„è‡ªåŠ¨å‡çº§

---

## 2. æŠ€æœ¯æ ˆ

### 2.1 æŠ€æœ¯æ ˆå…¨æ™¯å›¾

```mermaid
graph TB
    subgraph Frontend["å‰ç«¯å±‚"]
        A1["Next.js 15<br/>React 19"]
        A2["TypeScript"]
        A3["Zustand<br/>çŠ¶æ€ç®¡ç†"]
        A4["TanStack Query<br/>æ•°æ®è·å–"]
        A5["Tailwind CSS<br/>Shadcn/ui"]
    end

    subgraph API["API å±‚"]
        B1["FastAPI<br/>Python 3.11+"]
        B2["Pydantic v2<br/>éªŒè¯"]
        B3["Loguru<br/>æ—¥å¿—"]
    end

    subgraph Workflow["å·¥ä½œæµå±‚"]
        C1["LangGraph<br/>çŠ¶æ€æœº"]
        C2["AI-Prompter<br/>æ¨¡æ¿å¼•æ“"]
        C3["content-core<br/>å†…å®¹æå–"]
    end

    subgraph Data["æ•°æ®å±‚"]
        D1["SurrealDB<br/>å›¾æ•°æ®åº“"]
        D2["å‘é‡å­˜å‚¨<br/>è¯­ä¹‰æœç´¢"]
        D3["SQLite<br/>æ£€æŸ¥ç‚¹"]
    end

    subgraph AI["AI å±‚"]
        E1["Esperanto<br/>å¤šæä¾›å•†æŠ½è±¡"]
        E2["8+ AI Providers<br/>OpenAI/Anthropic/Ollamaç­‰"]
        E3["Embeddings<br/>TTS/STT"]
    end

    A1 --> B1
    B1 --> C1
    C1 --> D1
    C1 --> E1
    B1 --> D1
```

### 2.2 å‰ç«¯æŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|
| Next.js | 15 | React æ¡†æ¶ |
| React | 19 | UI åº“ |
| TypeScript | - | ç±»å‹å®‰å…¨ |
| Zustand | - | çŠ¶æ€ç®¡ç† |
| TanStack Query | - | æœåŠ¡ç«¯çŠ¶æ€ç®¡ç† |
| Tailwind CSS | - | æ ·å¼æ¡†æ¶ |
| Shadcn/ui | - | UI ç»„ä»¶åº“ |

### 2.3 åç«¯æŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|
| Python | 3.11+ | ä¸»è¦è¯­è¨€ |
| FastAPI | 0.104+ | Web æ¡†æ¶ |
| Pydantic | v2 | æ•°æ®éªŒè¯ |
| LangGraph | - | å·¥ä½œæµç¼–æ’ |
| SurrealDB | - | å›¾æ•°æ®åº“ |
| Esperanto | - | AI æä¾›å•†æŠ½è±¡ |

### 2.4 å¤–éƒ¨ä¾èµ–

- **content-core**: æ–‡ä»¶/URL å†…å®¹æå–ï¼ˆ50+ æ–‡ä»¶ç±»å‹ï¼‰
- **ai-prompter**: Jinja2 æ¨¡æ¿æ¸²æŸ“
- **surreal-commands**: å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—
- **tiktoken**: GPT token è®¡æ•°

---

## 3. æ•´ä½“æ¶æ„

### 3.1 ä¸‰å±‚æ¶æ„å›¾

```mermaid
graph TB
    subgraph Frontend["å‰ç«¯ Frontend (port 3000)"]
        UI[ç”¨æˆ·ç•Œé¢ / React/Next.js]
        State[Zustand State / TanStack Query]
    end

    subgraph API_Gateway["API Gateway (port 5055)"]
        Router[è·¯ç”±å±‚ / Routers]
        Middleware[CORS / Auth Middleware]
        Service[æœåŠ¡å±‚ / Services]
    end

    subgraph Business["ä¸šåŠ¡é€»è¾‘"]
        Graph[LangGraph å·¥ä½œæµ / çŠ¶æ€æœº]
        Domain[é¢†åŸŸæ¨¡å‹ / Domain Models]
        AI[AI æä¾›å•† / Esperanto]
    end

    subgraph Data["æ•°æ®æŒä¹…åŒ– (port 8000)"]
        DB[(SurrealDB / å›¾æ•°æ®åº“)]
        Vector[å‘é‡å­˜å‚¨ / è¯­ä¹‰æœç´¢]
        Files[æ–‡ä»¶å­˜å‚¨ / ä¸Šä¼ å†…å®¹]
    end

    subgraph Queue["ä»»åŠ¡é˜Ÿåˆ—"]
        Queue[Surreal-Commands / å¼‚æ­¥ä»»åŠ¡]
    end

    UI --> Router
    State --> Router
    Router --> Middleware
    Middleware --> Service
    Service --> Graph
    Service --> Domain
    Graph --> AI
    Domain --> DB
    Service --> DB
    Graph --> Queue
    Queue --> DB
```

### 3.2 æ¨¡å—ä¾èµ–å…³ç³»

```mermaid
graph LR
    subgraph API_Layer["API å±‚"]
        API[api/]
        Router[routers/]
        Service[*_service.py]
        Models[models.py]
    end

    subgraph Core_Layer["æ ¸å¿ƒå±‚"]
        ON[open_notebook/]
        Graph[graphs/]
        Domain[domain/]
    end

    subgraph Infrastructure["åŸºç¡€è®¾æ–½"]
        DB[database/]
        AI[ai/]
        Utils[utils/]
        Config[config.py]
    end

    Router --> Service
    Service --> Models
    Service --> Graph
    Service --> Domain
    Graph --> AI
    Graph --> Domain
    Domain --> DB
    Domain --> AI
    Graph --> Utils
    API --> Config
```

### 3.3 ç›®å½•ç»“æ„

```
open-notebook/
â”œâ”€â”€ frontend/                 # Next.js å‰ç«¯
â”‚   â”œâ”€â”€ app/                  # App Router
â”‚   â”œâ”€â”€ components/           # React ç»„ä»¶
â”‚   â”œâ”€â”€ lib/                  # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ stores/               # Zustand stores
â”‚
â”œâ”€â”€ api/                      # FastAPI åç«¯
â”‚   â”œâ”€â”€ routers/              # REST è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â”œâ”€â”€ notebooks.py
â”‚   â”‚   â”œâ”€â”€ sources.py
â”‚   â”‚   â”œâ”€â”€ notes.py
â”‚   â”‚   â”œâ”€â”€ podcasts.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ chat_service.py
â”‚   â”œâ”€â”€ podcast_service.py
â”‚   â”œâ”€â”€ sources_service.py
â”‚   â”œâ”€â”€ notes_service.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ main.py               # FastAPI åº”ç”¨å…¥å£
â”‚
â”œâ”€â”€ open_notebook/            # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ domain/               # é¢†åŸŸæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ base.py           # ObjectModel, RecordModel
â”‚   â”‚   â”œâ”€â”€ notebook.py       # Notebook, Source, Note
â”‚   â”‚   â””â”€â”€ content_settings.py
â”‚   â”œâ”€â”€ graphs/               # LangGraph å·¥ä½œæµ
â”‚   â”‚   â”œâ”€â”€ source.py         # å†…å®¹æ‘„å–
â”‚   â”‚   â”œâ”€â”€ chat.py           # å¯¹è¯
â”‚   â”‚   â”œâ”€â”€ ask.py            # æœç´¢åˆæˆ
â”‚   â”‚   â”œâ”€â”€ transformation.py # è½¬æ¢
â”‚   â”‚   â””â”€â”€ source_chat.py    # æºå¯¹è¯
â”‚   â”œâ”€â”€ ai/                   # AI æä¾›å•†ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ models.py         # ModelManager
â”‚   â”‚   â””â”€â”€ provision.py      # provision_langchain_model
â”‚   â”œâ”€â”€ database/             # æ•°æ®åº“å±‚
â”‚   â”‚   â”œâ”€â”€ repository.py     # CRUD æ“ä½œ
â”‚   â”‚   â””â”€â”€ async_migrate.py  # è‡ªåŠ¨è¿ç§»
â”‚   â”œâ”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ context_builder.py
â”‚   â”‚   â”œâ”€â”€ token_utils.py
â”‚   â”‚   â””â”€â”€ text_utils.py
â”‚   â”œâ”€â”€ podcasts/             # æ’­å®¢ç”Ÿæˆ
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ config.py             # é…ç½®
â”‚   â””â”€â”€ exceptions.py         # å¼‚å¸¸å®šä¹‰
â”‚
â”œâ”€â”€ commands/                 # å¼‚æ­¥ä»»åŠ¡å‘½ä»¤
â”‚   â”œâ”€â”€ embedding_commands.py
â”‚   â”œâ”€â”€ podcast_commands.py
â”‚   â””â”€â”€ source_commands.py
â”‚
â”œâ”€â”€ docs/                     # ç”¨æˆ·æ–‡æ¡£
â”œâ”€â”€ tests/                    # æµ‹è¯•
â””â”€â”€ docker-compose.yml        # éƒ¨ç½²é…ç½®
```

---

## 4. æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 4.1 API å±‚ (api/)

#### 4.1.1 æ¶æ„è®¾è®¡

```mermaid
graph TD
    Request[HTTP è¯·æ±‚] --> Router{è·¯ç”±åˆ†å‘}

    Router --> |POST /chat| ChatRouter
    Router --> |POST /sources| SourcesRouter
    Router --> |POST /podcasts| PodcastsRouter
    Router --> |GET /notebooks| NotebooksRouter

    ChatRouter --> ChatService[chat_service]
    SourcesRouter --> SourcesService[sources_service]
    PodcastsRouter --> PodcastService[podcast_service]
    NotebooksRouter --> NotebooksService[notebooks_service]

    ChatService --> ChatGraph[graphs/chat.py]
    SourcesService --> SourceGraph[graphs/source.py]
    PodcastService --> Queue[å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—]

    ChatGraph --> AI[AI æä¾›å•†]
    SourceGraph --> DB[(SurrealDB)]
    Queue --> DB
```

#### 4.1.2 å¯åŠ¨æµç¨‹

**api/main.py** æ˜¯åº”ç”¨çš„å…¥å£ç‚¹ï¼š

```python
# 1. ç¯å¢ƒå˜é‡åŠ è½½
load_dotenv()

# 2. Lifespan äº‹ä»¶å¤„ç†
@asynccontextmanager
async def lifespan(app: FastAPI):
    # å¯åŠ¨æ—¶ï¼šè‡ªåŠ¨è¿è¡Œæ•°æ®åº“è¿ç§»
    migration_manager = AsyncMigrationManager()
    if await migration_manager.needs_migration():
        await migration_manager.run_migration_up()

    yield

    # å…³é—­æ—¶ï¼šæ¸…ç†èµ„æº
    logger.info("API shutdown complete")

# 3. ä¸­é—´ä»¶é…ç½®
# - å¯†ç è®¤è¯ä¸­é—´ä»¶ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
# - CORS ä¸­é—´ä»¶ï¼ˆå…è®¸æ‰€æœ‰æºï¼‰
# - è‡ªå®šä¹‰å¼‚å¸¸å¤„ç†å™¨ï¼ˆç¡®ä¿ CORS å¤´ï¼‰

# 4. è·¯ç”±æ³¨å†Œ
app.include_router(auth.router, prefix="/api", tags=["auth"])
app.include_router(chat.router, prefix="/api", tags=["chat"])
# ... å…¶ä»–è·¯ç”±
```

**å…³é”®ç‰¹æ€§**ï¼š
- âœ… **è‡ªåŠ¨è¿ç§»**ï¼šæ¯æ¬¡å¯åŠ¨è‡ªåŠ¨æ£€æŸ¥å¹¶è¿è¡Œæ•°æ®åº“è¿ç§»
- âœ… **CORS æ”¯æŒ**ï¼šå‰åç«¯åˆ†ç¦»æ¶æ„å¿…éœ€
- âœ… **è®¤è¯ä¿æŠ¤**ï¼šæ‰€æœ‰ç«¯ç‚¹ï¼ˆé™¤é…ç½®/å¥åº·æ£€æŸ¥ï¼‰éœ€è¦è®¤è¯
- âœ… **å¼‚å¸¸å¤„ç†**ï¼šç»Ÿä¸€çš„é”™è¯¯å“åº”æ ¼å¼

#### 4.1.3 æœåŠ¡å±‚æ¨¡å¼

æ¯ä¸ªåŠŸèƒ½æ¨¡å—éƒ½æœ‰å¯¹åº”çš„æœåŠ¡ç±»ï¼š

| æœåŠ¡ç±» | èŒè´£ | å…³é”®æ–¹æ³• |
|--------|------|----------|
| `chat_service.py` | å¯¹è¯ç®¡ç† | `chat()`, å¤„ç†æ¶ˆæ¯å†å² |
| `sources_service.py` | å†…å®¹æ‘„å– | `create_source()`, è§¦å‘å‘é‡åŒ–å’Œè½¬æ¢ |
| `notes_service.py` | ç¬”è®°ç®¡ç† | `create_note()`, å…³è”æº/æ´å¯Ÿ |
| `podcast_service.py` | æ’­å®¢ç”Ÿæˆ | `generate_podcast()`, æäº¤å¼‚æ­¥ä»»åŠ¡ |
| `models_service.py` | æ¨¡å‹é…ç½® | `update_config()`, ç®¡ç†æä¾›å•† |
| `transformations_service.py` | å†…å®¹è½¬æ¢ | `apply_transformation()` |

**ç¤ºä¾‹ï¼šchat_service.py**

```python
class ChatService:
    async def chat(
        self,
        message: str,
        chat_session_id: str,
        model_override: Optional[str] = None
    ):
        # 1. åŠ è½½æˆ–åˆ›å»º ChatSession
        session = await ChatSession.get(chat_session_id)

        # 2. æ„å»ºä¸Šä¸‹æ–‡
        context = await ContextBuilder.build(
            notebook_id=session.notebook_id,
            token_budget=120000
        )

        # 3. è°ƒç”¨ chat.py å›¾
        config = {"configurable": {"model_id": model_override}} if model_override else {}
        response = await chat_graph.ainvoke(
            {"messages": [HumanMessage(content=message)], "context": context},
            config=config
        )

        # 4. è¿”å›å“åº”
        return {"response": response["messages"][-1].content}
```

### 4.2 é¢†åŸŸæ¨¡å‹å±‚ (open_notebook/domain/)

#### 4.2.1 åŸºç±»è®¾è®¡

**ObjectModel** - å¯å˜è®°å½•åŸºç±»

```mermaid
classDiagram
    class ObjectModel {
        +str id
        +datetime created
        +datetime updated
        +List[str] embedding
        +save() async
        +delete() async
        +relate(relationship, target)
        +get(id) static
        +get_all() static
    }

    class Notebook {
        +str name
        +str description
        +bool archived
        +get_sources()
        +get_notes()
        +get_chat_sessions()
    }

    class Source {
        +str title
        +str full_text
        +str url
        +RecordID command
        +vectorize()
        +get_context()
        +add_insight()
    }

    class Note {
        +str content
        +str type
        +add_to_notebook()
    }

    ObjectModel <|-- Notebook
    ObjectModel <|-- Source
    ObjectModel <|-- Note
```

**æ ¸å¿ƒç‰¹æ€§**ï¼š

1. **è‡ªåŠ¨æ—¶é—´æˆ³**ï¼š`created` å’Œ `updated` è‡ªåŠ¨ç®¡ç†
2. **è‡ªåŠ¨åµŒå…¥**ï¼š`save()` æ—¶å¦‚æœ `needs_embedding()` è¿”å› Trueï¼Œè‡ªåŠ¨ç”Ÿæˆå‘é‡
3. **å…³ç³»ç®¡ç†**ï¼š`relate()` æ–¹æ³•åˆ›å»º SurrealDB å›¾å…³ç³»
4. **å¤šæ€è·å–**ï¼š`ObjectModel.get(id)` æ ¹æ® ID å‰ç¼€è§£æå­ç±»
5. **æœç´¢æ”¯æŒ**ï¼šå†…ç½® `text_search()` å’Œ `vector_search()`

**RecordModel** - å•ä¾‹é…ç½®åŸºç±»

```python
class ContentSettings(RecordModel):
    record_id = "content_settings"
    # é…ç½®å­—æ®µ...

class DefaultPrompts(RecordModel):
    record_id = "default_prompts"
    # æç¤ºè¯æ¨¡æ¿...
```

#### 4.2.2 æ ¸å¿ƒé¢†åŸŸæ¨¡å‹

| æ¨¡å‹ | è¡¨å | ç”¨é€” | å…³ç³» |
|------|------|------|------|
| `Notebook` | notebook | ç ”ç©¶é¡¹ç›®å®¹å™¨ | â†’ Source (has), â†’ Note (artifact) |
| `Source` | source | å†…å®¹é¡¹ï¼ˆæ–‡ä»¶/URLï¼‰ | â† Notebook, â†’ Note (artifact), â†’ SourceInsight |
| `Note` | note | ç¬”è®° | â† Notebook, â† Source (refers_to) |
| `SourceInsight` | source_insight | æºæ´å¯Ÿ | â† Source |
| `SourceEmbedding` | source_embedding | æºå‘é‡åµŒå…¥ | â† Source |
| `ChatSession` | chat_session | å¯¹è¯ä¼šè¯ | â† Notebook, â†’ ChatMessage |
| `Asset` | asset | æ–‡ä»¶å¼•ç”¨ | â† Source |
| `Transformation` | transformation | å¯é‡ç”¨è½¬æ¢æç¤º | - |
| `ContentSettings` | content_settings | å†…å®¹å¤„ç†é…ç½® | - |
| `EpisodeProfile` | episode_profile | æ’­å®¢é…ç½® | - |
| `SpeakerProfile` | speaker_profile | è¯´è¯äººé…ç½® | - |
| `PodcastEpisode` | podcast_episode | æ’­å®¢ä»»åŠ¡ | - |

**å…³ç³»å›¾**ï¼š

```mermaid
graph LR
    Notebook[Notebook] -->|has| Source[Source]
    Notebook -->|artifact| Note[Note]
    Source -->|artifact| SourceInsight[SourceInsight]
    Note -->|refers_to| Source
    Notebook -->|refers_to| ChatSession[ChatSession]

    Source[Source] -->|async| Vectorize[å‘é‡åŒ–ä»»åŠ¡]
    ChatSession -->|generates| Podcast[PodcastEpisode]
```

#### 4.2.3 æ•°æ®æŒä¹…åŒ–

**ä¿å­˜æµç¨‹**ï¼š

```mermaid
sequenceDiagram
    participant Model as é¢†åŸŸæ¨¡å‹
    participant Repo as Repository
    participant DB as SurrealDB
    participant AI as ModelManager
    participant Queue as ä»»åŠ¡é˜Ÿåˆ—

    Model->>Repo: save()
    Repo->>DB: CREATE/UPDATE

    alt needs_embedding() == True
        Model->>AI: generate_embedding()
        AI->>AI: è°ƒç”¨åµŒå…¥æ¨¡å‹
        AI-->>Model: embeddingå‘é‡
        Model->>Repo: save() (å¸¦åµŒå…¥)
        Repo->>DB: UPDATE with embedding
    end

    alt is_large_source()
        Model->>Queue: submit_command(async_embed)
        Queue-->>Model: command_id
    end

    DB-->>Model: id, created, updated
```

**å…³é”®æ–¹æ³•**ï¼š

```python
# base.py
class ObjectModel(BaseModel):
    async def save(self) -> "ObjectModel":
        # 1. å‡†å¤‡æ•°æ®
        data = self._prepare_save_data()

        # 2. ç”ŸæˆåµŒå…¥
        if self.needs_embedding() and self.should_embed():
            embedding = await model_manager.get_embedding(
                text=self.get_embedding_text(),
                model_id=self.embedding_model
            )
            data["embedding"] = embedding

        # 3. åˆ›å»ºæˆ–æ›´æ–°
        if hasattr(self, 'id') and self.id:
            result = await repo_upsert(self.table_name, self.id, data)
        else:
            result = await repo_create(self.table_name, data)

        # 4. æ›´æ–°è‡ªèº«
        for key, value in result.items():
            setattr(self, key, value)

        return self
```

### 4.3 å·¥ä½œæµå±‚ (open_notebook/graphs/)

#### 4.3.1 LangGraph æ¶æ„

```mermaid
graph TB
    subgraph SourceGraph["source.py å†…å®¹æ‘„å–"]
        S1[content_process / æå–å†…å®¹]
        S2[save_source / ä¿å­˜æº]
        S3[trigger_transformations / è§¦å‘è½¬æ¢]
        S1 --> S2 --> S3
    end

    subgraph ChatGraph["chat.py å¯¹è¯"]
        C1[load_context / åŠ è½½ä¸Šä¸‹æ–‡]
        C2[call_model / è°ƒç”¨LLM]
        C3[persist_message / æŒä¹…åŒ–æ¶ˆæ¯]
        C1 --> C2 --> C3
    end

    subgraph AskGraph["ask.py æœç´¢åˆæˆ"]
        A1[search_sources / æœç´¢æº]
        A2[synthesize / åˆæˆç­”æ¡ˆ]
        A1 --> A2
    end

    subgraph TransformGraph["transformation.py è½¬æ¢"]
        T1[apply_prompt / åº”ç”¨æç¤º]
        T2[save_result / ä¿å­˜ç»“æœ]
        T1 --> T2
    end

    subgraph SourceChatGraph["source_chat.py æºå¯¹è¯"]
        SC1[load_source / åŠ è½½æº]
        SC2[chat_with_source / ä¸æºå¯¹è¯]
        SC1 --> SC2
    end
```

#### 4.3.2 source.py - å†…å®¹æ‘„å–å·¥ä½œæµ

**çŠ¶æ€å®šä¹‰**ï¼š

```python
class SourceState(TypedDict):
    source_id: str
    file_path: Optional[str]
    url: Optional[str]
    content: Optional[str]
    metadata: Optional[Dict[str, Any]]
    error: Optional[str]
```

**å·¥ä½œæµå›¾**ï¼š

```mermaid
stateDiagram-v2
    [*] --> Extract: æå–å†…å®¹
    Extract --> Save: ä¿å­˜æº
    Save --> Transform: è§¦å‘è½¬æ¢
    Transform --> [*]

    state Extract {
        [*] --> Extracting
        Extracting --> Extracted
        Extracted --> [*]
    }

    state Save {
        [*] --> Saving
        Saving --> Saved
        Saved --> [*]
    }

    state Transform {
        [*] --> Triggering
        Triggering --> Triggered
        Triggered --> [*]
    }
```

**å®ç°**ï¼š

```python
from langgraph.graph import StateGraph

async def content_process(state: SourceState) -> SourceState:
    """æå–æ–‡ä»¶æˆ– URL å†…å®¹"""
    from content_core import extract_content

    try:
        if state.get("file_path"):
            content, metadata = await extract_content(state["file_path"])
        elif state.get("url"):
            content, metadata = await extract_content(state["url"])
        else:
            raise ValueError("Either file_path or url required")

        state["content"] = content
        state["metadata"] = metadata
        return state
    except Exception as e:
        state["error"] = str(e)
        return state

async def save_source(state: SourceState) -> SourceState:
    """ä¿å­˜æºåˆ°æ•°æ®åº“"""
    source = await Source.get(state["source_id"])
    source.full_text = state["content"]
    # ä¿ç•™æ ‡é¢˜ï¼ˆå¦‚æœç”¨æˆ·æœªè®¾ç½®ï¼‰
    if not source.title and state["metadata"].get("title"):
        source.title = state["metadata"]["title"]
    await source.save()
    return state

async def trigger_transformations(state: SourceState) -> SourceState:
    """è§¦å‘æ‰€æœ‰è½¬æ¢ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰"""
    source = await Source.get(state["source_id"])
    transformations = await Transformation.get_all()

    # å¹¶è¡Œè§¦å‘
    tasks = [
        transformation_graph.ainvoke(
            {"source_id": str(source.id), "transformation_id": str(transformation.id)}
        )
        for transformation in transformations
    ]
    await asyncio.gather(*tasks)

    return state

# æ„å»ºå›¾
source_graph = StateGraph(SourceState)
source_graph.add_node("content_process", content_process)
source_graph.add_node("save_source", save_source)
source_graph.add_node("trigger_transformations", trigger_transformations)

source_graph.add_edge("content_process", "save_source")
source_graph.add_edge("save_source", "trigger_transformations")
source_graph.set_entry_point("content_process")

source_graph = source_graph.compile()
```

#### 4.3.3 chat.py - å¯¹è¯å·¥ä½œæµ

**çŠ¶æ€å®šä¹‰**ï¼š

```python
class ChatState(TypedDict):
    messages: List[BaseMessage]
    context: str
    notebook_id: str
    chat_session_id: str
    model_override: Optional[str]
```

**å·¥ä½œæµå›¾**ï¼š

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant API as API
    participant CB as ContextBuilder
    participant DB as Database
    participant Graph as chat.py
    participant AI as AI Provider
    participant SQLite as SqliteSaver

    User->>API: å‘é€æ¶ˆæ¯
    API->>CB: build_context(notebook_id)
    CB->>DB: æŸ¥è¯¢æº/ç¬”è®°
    DB-->>CB: è¿”å›å†…å®¹
    CB-->>API: è¿”å›ç»„è£…çš„ä¸Šä¸‹æ–‡

    API->>Graph: ainvoke(state, config)
    Graph->>AI: call_llm(messages, context)
    AI-->>Graph: è¿”å›å“åº”
    Graph->>SQLite: ä¿å­˜æ¶ˆæ¯åˆ°æ£€æŸ¥ç‚¹
    Graph-->>API: è¿”å› AI å“åº”
    API-->>User: è¿”å›å“åº”
```

**å®ç°**ï¼š

```python
from langgraph.checkpoint.sqlite import SqliteSaver

async def call_model(state: ChatState, config: RunnableConfig) -> ChatState:
    """è°ƒç”¨ LLM ç”Ÿæˆå“åº”"""
    # 1. å‡†å¤‡æ¨¡å‹
    model = await provision_langchain_model(
        type="language",
        model_id=state.get("model_override")
    )

    # 2. æ„å»ºæç¤º
    prompt = f"""Context: {state['context']}

Conversation History:
{format_messages(state['messages'][:-1])}

User: {state['messages'][-1].content}

Respond to the user's message based on the provided context."""

    # 3. è°ƒç”¨æ¨¡å‹
    response = await model.ainvoke(prompt)

    # 4. æ›´æ–°çŠ¶æ€
    state["messages"].append(AIMessage(content=response.content))
    return state

# æ„å»ºå›¾ï¼ˆå¸¦æ£€æŸ¥ç‚¹ï¼‰
chat_graph = StateGraph(ChatState)
chat_graph.add_node("call_model", call_model)
chat_graph.set_entry_point("call_model")

# SQLite æ£€æŸ¥ç‚¹å­˜å‚¨
checkpointer = SqliteSaver.from_conn_string(LANGGRAPH_CHECKPOINT_FILE)
chat_graph = chat_graph.compile(checkpointer=checkpointer)
```

### 4.4 AI æä¾›å•†å±‚ (open_notebook/ai/)

#### 4.4.1 Esperanto æŠ½è±¡

```mermaid
graph TB
    subgraph Application["åº”ç”¨å±‚"]
        App[Open Notebook]
    end

    subgraph Abstraction["æŠ½è±¡å±‚"]
        MM[ModelManager]
        PL[provision_langchain_model]
    end

    subgraph EsperantoLib["Esperanto åº“"]
        AI[AIProvider / ç»Ÿä¸€æ¥å£]
        Factory[AIFactory / å·¥å‚æ¨¡å¼]
    end

    subgraph Providers["æä¾›å•†å±‚"]
        OpenAI[OpenAI]
        Anthropic[Anthropic]
        Google[Google Gemini]
        Groq[Groq]
        Ollama[Ollama / æœ¬åœ°]
        Mistral[Mistral]
        DeepSeek[DeepSeek]
        xAI[xAI]
    end

    App --> MM
    MM --> PL
    PL --> Factory
    Factory --> AI
    AI --> OpenAI
    AI --> Anthropic
    AI --> Google
    AI --> Groq
    AI --> Ollama
    AI --> Mistral
    AI --> DeepSeek
    AI --> xAI
```

#### 4.4.2 ModelManager

**èŒè´£**ï¼š
- ç®¡ç†å¤šä¸ª AI æä¾›å•†çš„é…ç½®
- æ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼ˆåŸºäºä¸Šä¸‹æ–‡å¤§å°ï¼‰
- å¤±è´¥å›é€€é€»è¾‘
- æ¨¡å‹ç±»å‹æŠ½è±¡ï¼ˆlanguage, embedding, speech_to_text, text_to_speechï¼‰

**é…ç½®ç»“æ„**ï¼š

```python
class ModelManager:
    default_chat_model: str = "openai:gpt-4o-mini"
    default_large_context_model: str = "anthropic:claude-3-5-sonnet-20241022"
    default_embedding_model: str = "openai:text-embedding-3-small"

    # æ¨¡å‹ç±»å‹æ˜ å°„
    async def get_model(
        self,
        type: str,  # language, embedding, speech_to_text, text_to_speech
        model_id: Optional[str] = None
    ):
        if type == "language":
            return await self._get_language_model(model_id)
        elif type == "embedding":
            return await self._get_embedding_model(model_id)
        # ...
```

**æ™ºèƒ½é€‰æ‹©é€»è¾‘**ï¼š

```mermaid
flowchart TD
    Start[provision_langchain_model] --> CheckType{ç±»å‹?}

    CheckType -->|language| CheckContext{ä¸Šä¸‹æ–‡å¤§å°?}
    CheckType -->|embedding| GetEmbedding[è·å–é»˜è®¤åµŒå…¥æ¨¡å‹]
    CheckType -->|speech_to_text| GetSTT[è·å–é»˜è®¤ STT æ¨¡å‹]
    CheckType -->|text_to_speech| GetTTS[è·å–é»˜è®¤ TTS æ¨¡å‹]

    CheckContext -->|> 105K tokens| UseLarge[ä½¿ç”¨å¤§ä¸Šä¸‹æ–‡æ¨¡å‹]
    CheckContext -->|<= 105K tokens| UseDefault[ä½¿ç”¨é»˜è®¤èŠå¤©æ¨¡å‹]

    CheckOverride{æœ‰ model_override?}
    UseLarge --> CheckOverride
    UseDefault --> CheckOverride

    CheckOverride -->|æ˜¯| UseOverride[ä½¿ç”¨è¦†ç›–æ¨¡å‹]
    CheckOverride -->|å¦| ReturnModel[è¿”å›é€‰å®šæ¨¡å‹]

    UseOverride --> ReturnModel
    GetEmbedding --> ReturnModel
    GetSTT --> ReturnModel
    GetTTS --> ReturnModel

    ReturnModel --> End[è¿”å› LangChain Runnable]
```

**å…³é”®ç‰¹æ€§**ï¼š

1. **è‡ªåŠ¨å‡çº§**ï¼šå¤§ä¸Šä¸‹æ–‡è‡ªåŠ¨ä½¿ç”¨ `claude-3-5-sonnet`ï¼ˆ200K tokensï¼‰
2. **é…ç½®è¦†ç›–**ï¼šè¯·æ±‚çº§ `model_override` å‚æ•°
3. **å¤±è´¥å›é€€**ï¼šä¸»æ¨¡å‹å¤±è´¥æ—¶å›é€€åˆ°æ›´ä¾¿å®œçš„æ¨¡å‹
4. **ç±»å‹å®‰å…¨**ï¼šæ¯ç§ AI ç±»å‹æœ‰ç‹¬ç«‹çš„é»˜è®¤é…ç½®

#### 4.4.3 å¤šæä¾›å•†é›†æˆ

**æä¾›å•†æ˜ å°„**ï¼š

| æä¾›å•† | å‰ç¼€ | èŠå¤©æ¨¡å‹ | åµŒå…¥æ¨¡å‹ | æœ¬åœ° |
|--------|------|----------|----------|------|
| OpenAI | `openai:` | gpt-4o, gpt-4o-mini | text-embedding-3-small | âŒ |
| Anthropic | `anthropic:` | claude-3-5-sonnet, claude-3-haiku | - | âŒ |
| Google | `google:` | gemini-1.5-pro | - | âŒ |
| Groq | `groq:` | llama-3.3-70b | - | âŒ |
| Ollama | `ollama:` | llama3, mistral | - | âœ… |
| Mistral | `mistral:` | mistral-large | - | âŒ |
| DeepSeek | `deepseek:` | deepseek-chat | - | âŒ |
| xAI | `xai:` | grok-beta | - | âŒ |

### 4.5 æ•°æ®åº“å±‚ (open_notebook/database/)

#### 4.5.1 SurrealDB æ¶æ„

```mermaid
graph TB
    subgraph Application["åº”ç”¨å±‚"]
        App[FastAPI / LangGraph]
    end

    subgraph RepoLayer["Repository å±‚"]
        Repo[repository.py]
        Query[repo_query]
        Create[repo_create]
        Upsert[repo_upsert]
        Delete[repo_delete]
        Relate[repo_relate]
    end

    subgraph SurrealDriver["SurrealDB Driver"]
        Driver[AsyncSurreal Client]
        Connection[è¿æ¥æ± ]
    end

    subgraph SurrealServer["SurrealDB Server"]
        SurrealDB[SurrealDB / port 8000]
        NS[å‘½åç©ºé—´: open_notebook]
        DB[æ•°æ®åº“: main]
        Tables[è¡¨ & å…³ç³»]
        Vector[å‘é‡å­˜å‚¨]
    end

    App --> Repo
    Repo --> Query
    Repo --> Create
    Repo --> Upsert
    Repo --> Delete
    Repo --> Relate
    Query --> Driver
    Create --> Driver
    Upsert --> Driver
    Delete --> Driver
    Relate --> Driver
    Driver --> Connection
    Connection --> SurrealDB
    SurrealDB --> NS
    NS --> DB
    DB --> Tables
    DB --> Vector
```

#### 4.5.2 Repository æ¨¡å¼

**æ ¸å¿ƒå‡½æ•°**ï¼š

```python
# repository.py

async def repo_query(sql: str, params: Dict[str, Any]) -> List[Dict[str, Any]]:
    """æ‰§è¡Œ SurrealQL æŸ¥è¯¢"""
    async with AsyncSurreal("ws://localhost:8000/rpc") as db:
        await db.use("open_notebook", "main")
        return await db.query(sql, params)

async def repo_create(table: str, data: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ›å»ºè®°å½•"""
    async with AsyncSurreal("ws://localhost:8000/rpc") as db:
        await db.use("open_notebook", "main")
        return await db.create(table, data)

async def repo_upsert(table: str, id: Union[str, RecordID], data: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ›å»ºæˆ–æ›´æ–°è®°å½•"""
    async with AsyncSurreal("ws://localhost:8000/rpc") as db:
        await db.use("open_notebook", "main")
        return await db.upsert(table, id, data)

async def repo_relate(
    from_id: Union[str, RecordID],
    relation: str,
    to_id: Union[str, RecordID],
    data: Optional[Dict[str, Any]] = None
):
    """åˆ›å»ºå…³ç³»"""
    sql = f"RELATE {from_id}->{relation}->{to_id}"
    if data:
        sql += f" CONTENT {data}"
    return await repo_query(sql, {})
```

#### 4.5.3 æ•°æ®åº“æ¨¡å¼

**æ ¸å¿ƒè¡¨**ï¼š

```surrealql
-- Notebook è¡¨
DEFINE TABLE notebook SCHEMAFULL;
DEFINE FIELD name ON TABLE notebook TYPE string;
DEFINE FIELD description ON TABLE notebook TYPE string;
DEFINE FIELD archived ON TABLE notebook TYPE bool DEFAULT false;
DEFINE FIELD embedding ON TABLE notebook OPTION array;

-- Source è¡¨
DEFINE TABLE source SCHEMAFULL;
DEFINE FIELD title ON TABLE source TYPE string;
DEFINE FIELD full_text ON TABLE source TYPE string;
DEFINE FIELD url ON TABLE source TYPE string;
DEFINE FIELD command ON TABLE source TYPE record<table, command>;
DEFINE FIELD embedding ON TABLE source OPTION array;

-- Note è¡¨
DEFINE TABLE note SCHEMAFULL;
DEFINE FIELD content ON TABLE source TYPE string;
DEFINE FIELD type ON TABLE source TYPE string;
DEFINE FIELD embedding ON TABLE source OPTION array;

-- å…³ç³»
-- Notebook -> Source (has)
-- Notebook -> Note (artifact)
-- Note -> Source (refers_to)
-- Source -> SourceInsight
```

#### 4.5.4 è‡ªåŠ¨è¿ç§»

**è¿ç§»ç®¡ç†å™¨**ï¼š

```python
# async_migrate.py

class AsyncMigrationManager:
    MIGRATIONS_DIR = "./migrations"

    async def get_current_version(self) -> int:
        """è·å–å½“å‰æ•°æ®åº“ç‰ˆæœ¬"""
        result = await repo_query("SELECT * FROM version", {})
        return result[0]["number"] if result else 0

    async def needs_migration(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è¿ç§»"""
        current = await self.get_current_version()
        available = self._get_latest_migration_version()
        return current < available

    async def run_migration_up(self):
        """è¿è¡Œæ‰€æœ‰å¾…æ‰§è¡Œçš„è¿ç§»"""
        current = await self.get_current_version()
        for version in range(current + 1, self._get_latest_migration_version() + 1):
            migration_file = f"{self.MIGRATIONS_DIR}/{version:03d}_*.surql"
            sql = read_migration_file(migration_file)
            await repo_query(sql, {})
            await repo_query(f"UPDATE version SET number = {version}", {})
            logger.success(f"Migration {version} completed")
```

**è¿ç§»æ–‡ä»¶ç¤ºä¾‹**ï¼š

```
migrations/
â”œâ”€â”€ 001_init_schema.surql
â”œâ”€â”€ 002_add_vector_search.surql
â”œâ”€â”€ 003_add_podcast_tables.surql
â””â”€â”€ 004_add_transformation_tables.surql
```

### 4.6 å·¥å…·å±‚ (open_notebook/utils/)

#### 4.6.1 ContextBuilder

**èŒè´£**ï¼šä»å¤šä¸ªæ¥æºç»„è£… LLM ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶éµå®ˆ token é¢„ç®—ã€‚

```mermaid
graph TD
    Request[è¯·æ±‚ä¸Šä¸‹æ–‡] --> CB[ContextBuilder]

    CB --> LoadSources[åŠ è½½æº]
    CB --> LoadNotes[åŠ è½½ç¬”è®°]
    CB --> LoadInsights[åŠ è½½æ´å¯Ÿ]

    LoadSources --> CountTokens[è®¡ç®— tokens]
    LoadNotes --> CountTokens
    LoadInsights --> CountTokens

    CountTokens --> Budget{Token é¢„ç®—}

    Budget -->|æœªè¶…é¢„ç®—| AddContext[æ·»åŠ åˆ°ä¸Šä¸‹æ–‡]
    Budget -->|è¶…é¢„ç®—| Truncate[æˆªæ–­æˆ–ä¸¢å¼ƒ]

    AddContext --> Build[æ„å»ºæœ€ç»ˆä¸Šä¸‹æ–‡]
    Truncate --> Build

    Build --> Return[è¿”å›ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²]
```

**å®ç°**ï¼š

```python
class ContextBuilder:
    async def build(
        notebook_id: str,
        token_budget: int = 120000,
        sources_to_include: Optional[List[str]] = None
    ) -> str:
        """ç»„è£…ä¸Šä¸‹æ–‡"""
        notebook = await Notebook.get(notebook_id)

        # 1. åŠ è½½æºã€ç¬”è®°ã€æ´å¯Ÿ
        sources = await notebook.get_sources()
        notes = await notebook.get_notes()

        # 2. æŒ‰ä¼˜å…ˆçº§æ’åº
        # - æ˜¾å¼æŒ‡å®šçš„ sources ä¼˜å…ˆçº§æœ€é«˜
        # - æœ€è¿‘æ›´æ–°çš„å†…å®¹ä¼˜å…ˆçº§é«˜
        prioritized = _prioritize_content(sources, notes, sources_to_include)

        # 3. åœ¨ token é¢„ç®—å†…ç»„è£…
        context_parts = []
        current_tokens = 0

        for item in prioritized:
            item_tokens = count_tokens(item.get_context())
            if current_tokens + item_tokens <= token_budget:
                context_parts.append(item.get_context())
                current_tokens += item_tokens
            else:
                # æˆªæ–­æˆ–åœæ­¢
                break

        return "\n\n".join(context_parts)
```

**ä¼˜åŒ–ç­–ç•¥**ï¼š

1. **Token è®¡æ•°**ï¼šä½¿ç”¨ `tiktoken` å‡†ç¡®ä¼°ç®— GPT tokens
2. **ä¼˜å…ˆçº§æ’åº**ï¼š
   - æ˜¾å¼æŒ‡å®šçš„æº > è‡ªåŠ¨é€‰æ‹©çš„æº
   - æœ€è¿‘æ›´æ–° > æ—§å†…å®¹
   - ç¬”è®° > æºå†…å®¹
3. **æˆªæ–­ç­–ç•¥**ï¼š
   - é•¿å†…å®¹æˆªæ–­è€Œéå®Œå…¨ä¸¢å¼ƒ
   - ä¿ç•™å…³é”®éƒ¨åˆ†ï¼ˆå¼€å¤´/ç»“å°¾ï¼‰

#### 4.6.2 TokenUtils

```python
class TokenUtils:
    ENCODING = tiktoken.get_encoding("cl100k_base")

    @staticmethod
    def count_tokens(text: str) -> int:
        """è®¡ç®—æ–‡æœ¬çš„ GPT token æ•°é‡"""
        return len(TokenUtils.ENCODING.encode(text))

    @staticmethod
    def truncate_to_tokens(text: str, max_tokens: int) -> str:
        """æˆªæ–­æ–‡æœ¬åˆ°æŒ‡å®š token æ•°"""
        tokens = TokenUtils.ENCODING.encode(text)
        if len(tokens) <= max_tokens:
            return text
        truncated = tokens[:max_tokens]
        return TokenUtils.ENCODING.decode(truncated)
```

#### 4.6.3 TextUtils

```python
class TextUtils:
    @staticmethod
    def clean_text(text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼ˆç§»é™¤å¤šä½™ç©ºç™½ã€æ§åˆ¶å­—ç¬¦ï¼‰"""
        import re
        # ç§»é™¤æ§åˆ¶å­—ç¬¦
        text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
        # åˆå¹¶å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    @staticmethod
    def split_text(text: str, chunk_size: int, overlap: int = 100) -> List[str]:
        """åˆ†å‰²æ–‡æœ¬ä¸ºå—ï¼ˆå¸¦é‡å ï¼‰"""
        chunks = []
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            start = end - overlap
        return chunks
```

---

## 5. æ•°æ®æµåˆ†æ

### 5.1 å†…å®¹æ‘„å–æµç¨‹

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant UI as å‰ç«¯
    participant API as API
    participant Service as sources_service
    participant Graph as source.py
    participant Content as content-core
    participant DB as SurrealDB
    participant Queue as ä»»åŠ¡é˜Ÿåˆ—
    participant Embed as embedding_commands
    participant Trans as transformation.py

    User->>UI: ä¸Šä¼ æ–‡ä»¶/è¾“å…¥ URL
    UI->>API: POST /sources
    API->>Service: create_source()

    Service->>DB: åˆ›å»º Source è®°å½•
    DB-->>Service: source_id

    Service->>Graph: ainvoke(source_id)
    Graph->>Content: extract_content()
    Content-->>Graph: content, metadata

    Graph->>DB: ä¿å­˜ full_text, title

    Graph->>Queue: æäº¤å‘é‡åŒ–ä»»åŠ¡
    Queue-->>Graph: command_id

    Graph->>Trans: å¹¶è¡Œè§¦å‘æ‰€æœ‰è½¬æ¢
    Trans->>DB: ç”Ÿæˆ SourceInsight

    Graph-->>Service: å®Œæˆ
    Service-->>API: source_id, command_id
    API-->>UI: è¿”å›ç»“æœ
    UI-->>User: æ˜¾ç¤ºæˆåŠŸï¼Œcommand_id ç”¨äºè¿½è¸ª

    Note over Queue,Embed: å¼‚æ­¥å‘é‡åŒ–ï¼ˆåå°ï¼‰
    Queue->>Embed: æ‰§è¡ŒåµŒå…¥
    Embed->>AI: è°ƒç”¨åµŒå…¥æ¨¡å‹
    Embed->>DB: ä¿å­˜ SourceEmbedding
```

**å…³é”®ç‚¹**ï¼š
- âœ… **å¿«é€Ÿå“åº”**ï¼šç«‹å³è¿”å› `source_id`ï¼Œä¸ç­‰å¾…å‘é‡åŒ–å®Œæˆ
- âœ… **å¼‚æ­¥å¤„ç†**ï¼šå‘é‡åŒ–é€šè¿‡ä»»åŠ¡é˜Ÿåˆ—å¼‚æ­¥æ‰§è¡Œ
- âœ… **å¹¶è¡Œè½¬æ¢**ï¼šå¤šä¸ªè½¬æ¢å¹¶è¡Œæ‰§è¡Œ
- âœ… **å¯è¿½è¸ª**ï¼šè¿”å› `command_id` ç”¨äºè½®è¯¢çŠ¶æ€

### 5.2 å¯¹è¯æµç¨‹

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant UI as å‰ç«¯
    participant API as chat_service
    participant CB as ContextBuilder
    participant DB as SurrealDB
    participant Graph as chat.py
    participant AI as AI Provider
    participant Checkpoint as SqliteSaver

    User->>UI: å‘é€æ¶ˆæ¯
    UI->>API: POST /chat {message, session_id}
    API->>DB: åŠ è½½ ChatSession

    API->>CB: build_context(notebook_id)
    CB->>DB: æŸ¥è¯¢æºã€ç¬”è®°
    DB-->>CB: è¿”å›å†…å®¹
    CB-->>API: ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²

    API->>Graph: ainvoke(messages, context, config)
    Graph->>Checkpoint: åŠ è½½å†å²æ¶ˆæ¯
    Checkpoint-->>Graph: å†å²æ¶ˆæ¯

    Graph->>AI: ainvoke(prompt + context)
    AI-->>Graph: AI å“åº”

    Graph->>Checkpoint: ä¿å­˜æ–°æ¶ˆæ¯åˆ°æ£€æŸ¥ç‚¹

    Graph-->>API: AI å“åº”
    API-->>UI: è¿”å›å“åº”
    UI-->>User: æ˜¾ç¤º AI å›å¤
```

**çŠ¶æ€ç®¡ç†**ï¼š
- **æ¶ˆæ¯å†å²**ï¼šé€šè¿‡ SqliteSaver æŒä¹…åŒ–
- **ä¼šè¯éš”ç¦»**ï¼šæ¯ä¸ª `chat_session_id` ç‹¬ç«‹çš„æ£€æŸ¥ç‚¹
- **ä¸Šä¸‹æ–‡æ³¨å…¥**ï¼šæ¯æ¬¡è¯·æ±‚åŠ¨æ€ç»„è£…ä¸Šä¸‹æ–‡

### 5.3 æœç´¢åˆæˆæµç¨‹ (ask.py)

```mermaid
flowchart TD
    Start[ç”¨æˆ·æé—®] --> Search[vector_search]

    Search --> DB[(SurrealDB / å‘é‡æœç´¢)]
    DB --> Results[è¿”å›ç›¸å…³æº]

    Results --> BuildContext[ç»„è£…ä¸Šä¸‹æ–‡]
    BuildContext --> Synthesize[è°ƒç”¨ LLM åˆæˆ]

    Synthesize --> AI[AI Provider]
    AI --> Response[ç”Ÿæˆç­”æ¡ˆ]

    Response --> Citations[æ·»åŠ å¼•ç”¨]
    Citations --> End[è¿”å›ç­”æ¡ˆ+å¼•ç”¨]
```

**vs Chat çš„åŒºåˆ«**ï¼š
- âŒ æ— æ¶ˆæ¯å†å²
- âœ… æ¯æ¬¡ç‹¬ç«‹æœç´¢
- âœ… è¿”å›æºå¼•ç”¨

### 5.4 æ’­å®¢ç”Ÿæˆæµç¨‹

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant API as podcast_service
    participant Queue as surreal-commands
    participant Worker as podcast_commands
    participant AI as AI Provider
    participant TTS as TTS Engine
    participant DB as SurrealDB

    User->>API: POST /podcasts {sources, profile}
    API->>DB: åˆ›å»º PodcastEpisode (pending)

    API->>Queue: submit_command(generate_podcast)
    Queue-->>API: command_id
    API-->>User: è¿”å› command_id

    Note over Queue,Worker: åå°å¼‚æ­¥æ‰§è¡Œ

    Queue->>Worker: æ‰§è¡Œä»»åŠ¡
    Worker->>Worker: 1. ç”Ÿæˆå¤§çº² (outline.jinja)
    Worker->>AI: è°ƒç”¨ LLM ç”Ÿæˆç»“æ„
    AI-->>Worker: å¤§çº²

    Worker->>Worker: 2. ç”Ÿæˆé€å­—ç¨¿ (transcript.jinja)
    Worker->>AI: è°ƒç”¨ LLM å¡«å……å†…å®¹
    AI-->>Worker: é€å­—ç¨¿

    Worker->>TTS: 3. TTS åˆæˆ
    TTS->>TTS: æ¯ä¸ªè¯´è¯äººç‹¬ç«‹åˆæˆ
    TTS-->>Worker: éŸ³é¢‘ç‰‡æ®µ

    Worker->>Worker: 4. æ··éŸ³
    Worker->>DB: æ›´æ–° PodcastEpisode (completed)

    User->>API: GET /commands/{command_id}
    API-->>User: è¿”å›çŠ¶æ€å’Œç»“æœ
```

**å…³é”®ç‰¹æ€§**ï¼š
- âœ… **ä¸¤é˜¶æ®µç”Ÿæˆ**ï¼šå…ˆå¤§çº²ï¼Œåé€å­—ç¨¿
- âœ… **å¤šè¯´è¯äºº**ï¼š1-4 ä¸ªè¯´è¯äººï¼Œç‹¬ç«‹é…ç½®
- âœ… **å¼‚æ­¥å¤„ç†**ï¼šé•¿æ—¶é—´ä»»åŠ¡ä¸é˜»å¡ API
- âœ… **çŠ¶æ€è¿½è¸ª**ï¼šè½®è¯¢ `/commands/{id}` è·å–è¿›åº¦

---

## 6. æ¶æ„æ¨¡å¼

### 6.1 è®¾è®¡æ¨¡å¼

| æ¨¡å¼ | åº”ç”¨ä½ç½® | æè¿° |
|------|----------|------|
| **Repository** | `database/repository.py` | æ•°æ®è®¿é—®æŠ½è±¡ |
| **Factory** | `ai/models.py` | AI æ¨¡å‹åˆ›å»º |
| **State Machine** | `graphs/*.py` | LangGraph å·¥ä½œæµ |
| **Singleton** | `domain/base.py` (RecordModel) | é…ç½®å•ä¾‹ |
| **Observer** | `surreal-commands` | ä»»åŠ¡çŠ¶æ€ç›‘å¬ |
| **Strategy** | `ai/provision.py` | æ¨¡å‹é€‰æ‹©ç­–ç•¥ |
| **Builder** | `utils/context_builder.py` | ä¸Šä¸‹æ–‡ç»„è£… |
| **Template Method** | `domain/base.py` (ObjectModel) | ä¿å­˜/åˆ é™¤æ¨¡æ¿ |

### 6.2 åˆ†å±‚æ¶æ„

```mermaid
graph TB
    subgraph Presentation["è¡¨ç°å±‚"]
        UI[React UI / frontend/]
    end

    subgraph Application["åº”ç”¨å±‚"]
        Router[API Routers / api/routers/]
        Service[Services / api/*_service.py]
    end

    subgraph Domain["é¢†åŸŸå±‚"]
        Graph[LangGraph å·¥ä½œæµ / graphs/]
        Model[é¢†åŸŸæ¨¡å‹ / domain/]
    end

    subgraph Infrastructure["åŸºç¡€è®¾æ–½å±‚"]
        DB[Database / database/]
        AI[AI Providers / ai/]
        Utils[Utilities / utils/]
    end

    UI --> Router
    Router --> Service
    Service --> Graph
    Service --> Model
    Graph --> Model
    Graph --> AI
    Model --> DB
    Service --> DB
```

**ä¾èµ–è§„åˆ™**ï¼š
- âœ… ä¸Šå±‚å¯ä»¥ä¾èµ–ä¸‹å±‚
- âŒ ä¸‹å±‚ä¸èƒ½ä¾èµ–ä¸Šå±‚
- âœ… åŒå±‚ä¹‹é—´é€šè¿‡æ¥å£äº¤äº’

### 6.3 å¼‚æ­¥æ¨¡å¼

**å…¨æ ˆå¼‚æ­¥**ï¼š

```mermaid
sequenceDiagram
    participant Client
    participant API as FastAPI
    participant DB as SurrealDB
    participant AI as AI Provider
    participant Queue as ä»»åŠ¡é˜Ÿåˆ—

    Client->>API: async HTTP è¯·æ±‚
    API->>DB: async repo_query()
    DB-->>API: async ç»“æœ

    API->>AI: async model.ainvoke()
    AI-->>API: async å“åº”

    API->>Queue: async submit_command()
    Queue-->>API: async command_id

    API-->>Client: async å“åº”
```

**ä¼˜åŠ¿**ï¼š
- âœ… é«˜å¹¶å‘å¤„ç†
- âœ… éé˜»å¡ I/O
- âœ… èµ„æºé«˜æ•ˆåˆ©ç”¨

### 6.4 CQRS æ¨¡å¼

**å‘½ä»¤æŸ¥è¯¢è´£ä»»åˆ†ç¦»**ï¼š

```python
# Commandï¼ˆå†™æ“ä½œï¼‰
class NotebookCommand:
    async def create_notebook(name: str, description: str) -> Notebook:
        notebook = Notebook(name=name, description=description)
        return await notebook.save()

    async def update_notebook(id: str, **kwargs) -> Notebook:
        notebook = await Notebook.get(id)
        for key, value in kwargs.items():
            setattr(notebook, key, value)
        return await notebook.save()

# Queryï¼ˆè¯»æ“ä½œï¼‰
class NotebookQuery:
    async def get_notebook(id: str) -> Notebook:
        return await Notebook.get(id)

    async def search_notebooks(keyword: str) -> List[Notebook]:
        return await text_search(keyword, table="notebook")

    async def get_notebook_sources(id: str) -> List[Source]:
        notebook = await Notebook.get(id)
        return await notebook.get_sources()
```

---

## 7. å…³é”®è®¾è®¡å†³ç­–

### 7.1 ä¸ºä»€ä¹ˆé€‰æ‹© SurrealDBï¼Ÿ

| ç‰¹æ€§ | SurrealDB | PostgreSQL + pgvector | MongoDB + Atlas Vector |
|------|-----------|----------------------|----------------------|
| **å›¾å…³ç³»** | âœ… åŸç”Ÿæ”¯æŒ | âŒ éœ€è¦é¢å¤–è¡¨ | âœ… åŸç”Ÿæ”¯æŒ |
| **å‘é‡æœç´¢** | âœ… å†…ç½® | âœ… pgvector æ‰©å±• | âœ… Atlas Vector |
| **ACID äº‹åŠ¡** | âœ… | âœ… | âœ… |
| **æŸ¥è¯¢è¯­è¨€** | SurrealQL | SQL | MongoDB Query |
| **å­¦ä¹ æ›²çº¿** | ä¸­ç­‰ | ä½ | ä¸­ç­‰ |
| **éƒ¨ç½²å¤æ‚åº¦** | å•ä¸€äºŒè¿›åˆ¶ | éœ€è¦æ‰©å±•é…ç½® | äº‘æœåŠ¡å¤æ‚ |

**å†³ç­–ç†ç”±**ï¼š
1. **ç»Ÿä¸€æ–¹æ¡ˆ**ï¼šå›¾å…³ç³» + å‘é‡æœç´¢åœ¨ä¸€ä¸ªæ•°æ®åº“ä¸­
2. **ç®€åŒ–æ¶æ„**ï¼šæ— éœ€å¤šä¸ªæ•°æ®å­˜å‚¨
3. **åŸç”Ÿæ”¯æŒ**ï¼šæ— éœ€æ‰©å±•æˆ–æ’ä»¶
4. **ç°ä»£è®¾è®¡**ï¼šä¸“ä¸ºç°ä»£åº”ç”¨è®¾è®¡

**æƒè¡¡**ï¼š
- âŒ ç”Ÿæ€è¾ƒæ–°ï¼Œç¤¾åŒºè¾ƒå°
- âŒ å·¥å…·é“¾ä¸å¦‚ PostgreSQL æˆç†Ÿ
- âœ… å¼€å‘æ•ˆç‡é«˜

### 7.2 ä¸ºä»€ä¹ˆä½¿ç”¨ LangGraphï¼Ÿ

| æ¡†æ¶ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|------|------|------|
| **LangGraph** | çŠ¶æ€ç®¡ç†ã€æ£€æŸ¥ç‚¹ã€å¯è§†åŒ– | å­¦ä¹ æ›²çº¿ |
| **ç›´æ¥ç¼–ç ** | ç®€å•ç›´æ¥ | éš¾ä»¥ç»´æŠ¤ã€æ— æ£€æŸ¥ç‚¹ |
| **Airflow** | æˆç†Ÿã€DAG | è¿‡é‡ã€ä¸é€‚åˆå®æ—¶ |

**å†³ç­–ç†ç”±**ï¼š
1. **çŠ¶æ€æŒä¹…åŒ–**ï¼šSQLite æ£€æŸ¥ç‚¹è‡ªåŠ¨ä¿å­˜
2. **å¯è§†åŒ–**ï¼šå¯å¯¼å‡º Mermaid å›¾
3. **LangChain ç”Ÿæ€**ï¼šä¸ LangChain æ— ç¼é›†æˆ
4. **å¼‚æ­¥æ”¯æŒ**ï¼šåŸç”Ÿ async/await

### 7.3 ä¸ºä»€ä¹ˆå…¨å¼‚æ­¥ï¼Ÿ

```python
# âŒ åŒæ­¥ç‰ˆæœ¬ï¼ˆé˜»å¡ï¼‰
def create_source(file_path: str) -> Source:
    content = extract_content_sync(file_path)  # é˜»å¡ I/O
    embedding = generate_embedding_sync(content)  # é˜»å¡ç½‘ç»œ
    source = Source(title=..., full_text=content)
    source.save_sync()  # é˜»å¡æ•°æ®åº“
    return source

# âœ… å¼‚æ­¥ç‰ˆæœ¬ï¼ˆéé˜»å¡ï¼‰
async def create_source(file_path: str) -> Source:
    content = await extract_content_async(file_path)  # éé˜»å¡
    embedding = await generate_embedding_async(content)  # éé˜»å¡
    source = Source(title=..., full_text=content)
    await source.save_async()  # éé˜»å¡
    return source
```

**æ€§èƒ½å¯¹æ¯”**ï¼š

| æŒ‡æ ‡ | åŒæ­¥ç‰ˆæœ¬ | å¼‚æ­¥ç‰ˆæœ¬ |
|------|----------|----------|
| **å¹¶å‘è¯·æ±‚** | 1 worker | 1000+ å¹¶å‘ |
| **èµ„æºåˆ©ç”¨ç‡** | ä½ï¼ˆç­‰å¾… I/Oï¼‰ | é«˜ï¼ˆå¤„ç†å…¶ä»–è¯·æ±‚ï¼‰ |
| **å“åº”æ—¶é—´** | ä¸²è¡Œç´¯åŠ  | æœ€é•¿æ“ä½œæ—¶é—´ |

### 7.4 ä¸ºä»€ä¹ˆåˆ†ç¦»å‰ç«¯å’Œåç«¯ï¼Ÿ

**Monorepo vs Multi-repo**ï¼š

```
å½“å‰æ¶æ„ï¼šMonorepo
open-notebook/
â”œâ”€â”€ frontend/     # Next.js
â”œâ”€â”€ api/          # FastAPI
â””â”€â”€ open_notebook/ # å…±äº«ç±»å‹ï¼Ÿ

ä¼˜åŠ¿ï¼š
âœ… ç»Ÿä¸€ç‰ˆæœ¬ç®¡ç†
âœ… å…±äº«ä»£ç å’Œæ–‡æ¡£
âœ… ç®€åŒ– CI/CD

åŠ£åŠ¿ï¼š
âŒ éƒ¨ç½²è€¦åˆ
âŒ æŠ€æœ¯æ ˆç‹¬ç«‹ä½†åœ¨ä¸€èµ·
```

**å†³ç­–**ï¼šMonorepo + ç‹¬ç«‹éƒ¨ç½²
- å‰ç«¯ï¼š`docker run frontend:3000`
- åç«¯ï¼š`docker run api:5055`
- æ•°æ®åº“ï¼š`docker run surrealdb:8000`

### 7.5 ä¸ºä»€ä¹ˆä½¿ç”¨ä»»åŠ¡é˜Ÿåˆ—ï¼Ÿ

**åŒæ­¥ vs å¼‚æ­¥**ï¼š

```mermaid
graph TB
    subgraph Sync["åŒæ­¥æ–¹å¼"]
        S1[ä¸Šä¼ æ–‡ä»¶] --> S2[å‘é‡åŒ– 30s]
        S2 --> S3[è¿”å›ç»“æœ]
        S3 -.é˜»å¡.-> S2
    end

    subgraph Async["å¼‚æ­¥æ–¹å¼"]
        A1[ä¸Šä¼ æ–‡ä»¶] --> A2[æäº¤ä»»åŠ¡]
        A2 --> A3[ç«‹å³è¿”å› command_id]
        A2 --> A4[åå°å‘é‡åŒ– 30s]
    end
```

**é€‰æ‹©å¼‚æ­¥ç†ç”±**ï¼š
1. **ç”¨æˆ·ä½“éªŒ**ï¼šä¸é˜»å¡ UI
2. **å¯æ‰©å±•æ€§**ï¼šä»»åŠ¡å¯åˆ†å‘åˆ°å¤šä¸ª worker
3. **å®¹é”™æ€§**ï¼šä»»åŠ¡å¤±è´¥å¯é‡è¯•
4. **å¯è§‚æµ‹æ€§**ï¼šçŠ¶æ€è¿½è¸ª

---

## 8. æ‰©å±•æ€§åˆ†æ

### 8.1 æ°´å¹³æ‰©å±•

```mermaid
graph TB
    subgraph LoadBalancer["è´Ÿè½½å‡è¡¡å±‚"]
        LB[Nginx / Traefik]
    end

    subgraph API_Layer["API å±‚"]
        API1[API å®ä¾‹ 1 / :5055]
        API2[API å®ä¾‹ 2 / :5055]
        API3[API å®ä¾‹ N / :5055]
    end

    subgraph Queue["ä»»åŠ¡é˜Ÿåˆ—"]
        Queue[surreal-commands]
        Worker1[Worker 1]
        Worker2[Worker 2]
        WorkerN[Worker N]
    end

    subgraph Database["æ•°æ®åº“å±‚"]
        DB[(SurrealDB Cluster / åˆ†å¸ƒå¼)]
    end

    LB --> API1
    LB --> API2
    LB --> API3

    API1 --> Queue
    API2 --> Queue
    API3 --> Queue

    Queue --> Worker1
    Queue --> Worker2
    Queue --> WorkerN

    API1 --> DB
    API2 --> DB
    API3 --> DB
    Worker1 --> DB
    Worker2 --> DB
    WorkerN --> DB
```

**æ‰©å±•ç‚¹**ï¼š
1. **API å±‚**ï¼šæ— çŠ¶æ€æœåŠ¡ï¼Œå¯æ°´å¹³æ‰©å±•
2. **Worker å±‚**ï¼šä»»åŠ¡é˜Ÿåˆ—å¯ç‹¬ç«‹æ‰©å±•
3. **æ•°æ®åº“å±‚**ï¼šSurrealDB åˆ†å¸ƒå¼æ¨¡å¼

### 8.2 å‚ç›´æ‰©å±•

**èµ„æºä¼˜åŒ–**ï¼š

| ç»„ä»¶ | CPU å¯†é›† | I/O å¯†é›† | å†…å­˜å¯†é›† | æ‰©å±•å»ºè®® |
|------|----------|----------|----------|----------|
| FastAPI | âŒ | âœ… | âŒ | å¢åŠ å¹¶å‘è¿æ¥ |
| LangGraph | âœ… | âŒ | âœ… | æ›´å¿« CPU/æ›´å¤š RAM |
| SurrealDB | âœ… | âœ… | âœ… | æ›´å¿« CPU + æ›´å¤š RAM + SSD |
| Embedding | âŒ | âœ… | âŒ | GPU åŠ é€Ÿ |

### 8.3 åŠŸèƒ½æ‰©å±•

**æ·»åŠ æ–°çš„ AI æä¾›å•†**ï¼š

```python
# 1. åœ¨ Esperanto ä¸­å®ç°
class NewAIProvider(AIProvider):
    async def chat(): ...

# 2. åœ¨ ModelManager ä¸­æ³¨å†Œ
default_newai_model = "newai:model-name"

# 3. åœ¨é…ç½®ä¸­æ·»åŠ 
AI_PROVIDERS["newai"] = NewAIProvider()
```

**æ·»åŠ æ–°çš„å†…å®¹ç±»å‹**ï¼š

```python
# 1. æ‰©å±• content-core
async def extract_content_from_new_format(file_path: str) -> Tuple[str, Dict]:
    # å®ç°æå–é€»è¾‘
    pass

# 2. åœ¨ source.py ä¸­ä½¿ç”¨
@content_process.register("new_format")
async def process_new_format(state: SourceState) -> SourceState:
    content, metadata = await extract_content_from_new_format(state["file_path"])
    state["content"] = content
    state["metadata"] = metadata
    return state
```

**æ·»åŠ æ–°çš„å·¥ä½œæµ**ï¼š

```python
# 1. åˆ›å»ºæ–°çš„ graph
# open_notebook/graphs/new_workflow.py

class NewWorkflowState(TypedDict):
    input: str
    output: str

async def process_step_1(state: NewWorkflowState) -> NewWorkflowState:
    # å¤„ç†é€»è¾‘
    return state

async def process_step_2(state: NewWorkflowState) -> NewWorkflowState:
    # å¤„ç†é€»è¾‘
    return state

# 2. æ„å»ºå›¾
graph = StateGraph(NewWorkflowState)
graph.add_node("step1", process_step_1)
graph.add_node("step2", process_step_2)
graph.add_edge("step1", "step2")
graph.set_entry_point("step1")
workflow = graph.compile()

# 3. ä» API è°ƒç”¨
# api/routers/new_feature.py
@router.post("/new-workflow")
async def run_new_workflow(input: str):
    result = await workflow.ainvoke({"input": input})
    return result
```

---

## 9. å®‰å…¨æ€§è€ƒè™‘

### 9.1 å½“å‰å®‰å…¨æœºåˆ¶

| å®‰å…¨å±‚é¢ | å®ç° | çŠ¶æ€ |
|----------|------|------|
| **è®¤è¯** | `PasswordAuthMiddleware` | âš ï¸ ä»…å¼€å‘ç¯å¢ƒ |
| **CORS** | å…è®¸æ‰€æœ‰æº | âš ï¸ éœ€è¦é…ç½® |
| **SQL æ³¨å…¥** | SurrealQL å‚æ•°åŒ–æŸ¥è¯¢ | âœ… å®‰å…¨ |
| **XSS** | React è‡ªåŠ¨è½¬ä¹‰ | âœ… å®‰å…¨ |
| **CSRF** | æœªå®ç° | âŒ éœ€è¦æ·»åŠ  |
| **æ–‡ä»¶ä¸Šä¼ ** | ç±»å‹éªŒè¯ | âš ï¸ åŸºç¡€ |
| **æ•æ„Ÿæ•°æ®** | ç¯å¢ƒå˜é‡ | âœ… å®‰å…¨ |
| **API é™æµ** | æœªå®ç° | âŒ éœ€è¦æ·»åŠ  |

### 9.2 ç”Ÿäº§ç¯å¢ƒå»ºè®®

**è®¤è¯å‡çº§**ï¼š

```python
# âŒ å½“å‰ï¼ˆä¸å®‰å…¨ï¼‰
class PasswordAuthMiddleware:
    async def check_password(self, password: str) -> bool:
        return password == os.getenv("API_PASSWORD")

# âœ… ç”Ÿäº§ç¯å¢ƒï¼ˆJWTï¼‰
class JWTAuthMiddleware:
    async def verify_token(self, token: str) -> bool:
        try:
            payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
            return True
        except JWTError:
            return False
```

**CORS é…ç½®**ï¼š

```python
# âŒ å½“å‰ï¼ˆä¸å®‰å…¨ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æº
)

# âœ… ç”Ÿäº§ç¯å¢ƒ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://open-notebook.ai"],  # æŒ‡å®šæº
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["Authorization"],
)
```

**æ–‡ä»¶ä¸Šä¼ å®‰å…¨**ï¼š

```python
# âœ… æ·»åŠ éªŒè¯
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
ALLOWED_EXTENSIONS = {".pdf", ".txt", ".md", ".docx"}

async def validate_upload(file: UploadFile):
    # 1. å¤§å°æ£€æŸ¥
    content = await file.read()
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(400, "File too large")

    # 2. ç±»å‹æ£€æŸ¥
    ext = os.path.splitext(file.filename)[1].lower()
    if ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(400, "File type not allowed")

    # 3. ç—…æ¯’æ‰«æï¼ˆå¯é€‰ï¼‰
    # scan_for_viruses(content)
```

### 9.3 æ•°æ®å®‰å…¨

**æ•æ„Ÿå­—æ®µä¿æŠ¤**ï¼š

```python
class Source(BaseModel):
    title: str
    full_text: str  # âš ï¸ å¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯
    # âœ… æ·»åŠ è®¿é—®æ§åˆ¶
    async def get_full_text(self, user_id: str) -> str:
        if await self.check_access(user_id):
            return self.full_text
        raise PermissionError("Access denied")
```

**åŠ å¯†å­˜å‚¨**ï¼š

```python
from cryptography.fernet import Fernet

class EncryptedField(str):
    """åŠ å¯†å­—æ®µ"""

    @classmethod
    def encrypt(cls, plaintext: str) -> "EncryptedField":
        f = Fernet(ENCRYPTION_KEY)
        return cls(f.encrypt(plaintext.encode()).decode())

    def decrypt(self) -> str:
        f = Fernet(ENCRYPTION_KEY)
        return f.decrypt(self.encode()).decode()
```

---

## 10. æ€§èƒ½ä¼˜åŒ–

### 10.1 æ•°æ®åº“ä¼˜åŒ–

**ç´¢å¼•ç­–ç•¥**ï¼š

```surrealql
-- âœ… åˆ›å»ºç´¢å¼•
CREATE INDEX on_embed_field ON source (embedding OPTIONS { vector_index_type: "hsnw" });
CREATE INDEX on_notebook_name ON notebook (name);
CREATE INDEX on_source_title ON source (title);

-- âœ… ä¼˜åŒ–æŸ¥è¯¢
-- ä½¿ç”¨ç´¢å¼•å­—æ®µ
SELECT * FROM source WHERE title @ "keyword";  -- ä½¿ç”¨ç´¢å¼•

-- âŒ é¿å…å…¨è¡¨æ‰«æ
SELECT * FROM source WHERE full_text CONTAINS "keyword";  -- å…¨è¡¨æ‰«æ
```

**æŸ¥è¯¢ä¼˜åŒ–**ï¼š

```python
# âŒ N+1 æŸ¥è¯¢
async def get_notebooks_with_sources():
    notebooks = await Notebook.get_all()
    for notebook in notebooks:
        sources = await notebook.get_sources()  # N æ¬¡æŸ¥è¯¢
        notebook.sources = sources
    return notebooks

# âœ… ä¸€æ¬¡æŸ¥è¯¢
async def get_notebooks_with_sources():
    result = await repo_query("""
        SELECT
            notebook.*,
            array::distinct(in.source) as sources
        FROM notebook
        FETCH in, source
    """, {})
    return result
```

### 10.2 ç¼“å­˜ç­–ç•¥

**Redis ç¼“å­˜**ï¼š

```python
import redis
import json

cache = redis.Redis(host="localhost", port=6379)

class CachedNotebook:
    @staticmethod
    async def get(id: str) -> Notebook:
        # 1. å°è¯•ä»ç¼“å­˜è¯»å–
        cached = cache.get(f"notebook:{id}")
        if cached:
            return Notebook(**json.loads(cached))

        # 2. ä»æ•°æ®åº“è¯»å–
        notebook = await Notebook.get(id)

        # 3. å†™å…¥ç¼“å­˜ï¼ˆTTL 1 å°æ—¶ï¼‰
        cache.setex(f"notebook:{id}", 3600, notebook.model_dump_json())
        return notebook
```

**ç¼“å­˜å±‚çº§**ï¼š

```mermaid
graph LR
    A[è¯·æ±‚] --> B{L1 ç¼“å­˜ / å†…å­˜}
    B -->|å‘½ä¸­| C[è¿”å›]
    B -->|æœªå‘½ä¸­| D{L2 ç¼“å­˜ / Redis}
    D -->|å‘½ä¸­| C
    D -->|æœªå‘½ä¸­| E[(æ•°æ®åº“)]
    E --> F[æ›´æ–°ç¼“å­˜]
    F --> C
```

### 10.3 å¹¶å‘ä¼˜åŒ–

**è¿æ¥æ± **ï¼š

```python
# âŒ æ¯æ¬¡åˆ›å»ºæ–°è¿æ¥
async def query_surreal(sql: str):
    async with AsyncSurreal("ws://localhost:8000/rpc") as db:
        return await db.query(sql)

# âœ… è¿æ¥æ± 
from surrealdb import AsyncSurrealPool

pool = AsyncSurrealPool(
    "ws://localhost:8000/rpc",
    min_size=5,
    max_size=20
)

async def query_surreal(sql: str):
    async with pool.acquire() as db:
        return await db.query(sql)
```

**æ‰¹é‡æ“ä½œ**ï¼š

```python
# âŒ é€ä¸ªåˆ›å»º
async def create_sources(sources: List[Dict]):
    for source_data in sources:
        source = Source(**source_data)
        await source.save()  # N æ¬¡æ•°æ®åº“å¾€è¿”

# âœ… æ‰¹é‡åˆ›å»º
async def create_sources(sources: List[Dict]):
    # SurrealDB æ”¯æŒæ‰¹é‡æ’å…¥
    sql = "SELECT * FROM create_source($sources)"
    return await repo_query(sql, {"sources": sources})
```

### 10.4 å‰ç«¯ä¼˜åŒ–

**ä»£ç åˆ†å‰²**ï¼š

```typescript
// âœ… è·¯ç”±çº§åˆ«ä»£ç åˆ†å‰²
const ChatPage = lazy(() => import("./pages/ChatPage"));
const PodcastPage = lazy(() => import("./pages/PodcastPage"));

function App() {
    return (
        <Suspense fallback={<Loading />}>
            <Routes>
                <Route path="/chat" element={<ChatPage />} />
                <Route path="/podcast" element={<PodcastPage />} />
            </Routes>
        </Suspense>
    );
}
```

**æ•°æ®é¢„å–**ï¼š

```typescript
// âœ… é¢„å–ä¸‹ä¸€é¡µæ•°æ®
const { data } = useQuery(["notebooks"], fetchNotebooks);

useEffect(() => {
    if (data?.hasNextPage) {
        queryClient.prefetchQuery(
            ["notebooks", data.nextPage],
            () => fetchNotebooks(data.nextPage)
        );
    }
}, [data]);
```

---

## 11. éƒ¨ç½²æ¶æ„

### 11.1 å¼€å‘ç¯å¢ƒ

```yaml
# docker-compose.dev.yml
version: "3.8"

services:
  surrealdb:
    image: surrealdb/surrealdb:latest
    ports:
      - "8000:8000"
    volumes:
      - ./data:/data

  api:
    build: .
    ports:
      - "5055:5055"
    environment:
      - SURREALDB_URL=ws://surrealdb:8000/rpc
    depends_on:
      - surrealdb

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:5055
```

**å¯åŠ¨**ï¼š

```bash
docker-compose -f docker-compose.dev.yml up
```

### 11.2 ç”Ÿäº§ç¯å¢ƒ

```yaml
# docker-compose.prod.yml
version: "3.8"

services:
  # è´Ÿè½½å‡è¡¡
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - api
      - frontend

  # API é›†ç¾¤
  api:
    image: open-notebook-api:latest
    deploy:
      replicas: 3
    environment:
      - SURREALDB_URL=ws://surrealdb:8000/rpc
      - ENVIRONMENT=production
    depends_on:
      - surrealdb

  # Worker é›†ç¾¤
  worker:
    image: open-notebook-worker:latest
    deploy:
      replicas: 2
    environment:
      - SURREALDB_URL=ws://surrealdb:8000/rpc

  # SurrealDB é›†ç¾¤
  surrealdb:
    image: surrealdb/surrealdb:latest
    ports:
      - "8000:8000"
    volumes:
      - ./data:/data
    deploy:
      replicas: 1

  # å‰ç«¯ï¼ˆCDNï¼‰
  frontend:
    image: open-notebook-frontend:latest
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=https://api.open-notebook.ai
```

### 11.3 Kubernetes éƒ¨ç½²

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: open-notebook-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
      - name: api
        image: open-notebook-api:latest
        ports:
        - containerPort: 5055
        env:
        - name: SURREALDB_URL
          value: "ws://surrealdb-service:8000/rpc"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 5055
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 5055
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: api-service
spec:
  selector:
    app: api
  ports:
  - protocol: TCP
    port: 5055
    targetPort: 5055
  type: LoadBalancer
```

### 11.4 ç›‘æ§å’Œæ—¥å¿—

**æ—¥å¿—èšåˆ**ï¼š

```python
from loguru import logger

# é…ç½®ç»“æ„åŒ–æ—¥å¿—
logger.add(
    "logs/api_{time}.log",
    rotation="1 day",
    retention="30 days",
    compression="zip",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} | {message}",
    enqueue=True,  # å¼‚æ­¥å†™å…¥
)

# ä½¿ç”¨
logger.info("Source created", extra={"source_id": str(source.id), "user_id": user_id})
```

**æŒ‡æ ‡ç›‘æ§**ï¼š

```python
from prometheus_client import Counter, Histogram

# å®šä¹‰æŒ‡æ ‡
source_created_counter = Counter(
    "sources_created_total",
    "Total sources created"
)

chat_duration = Histogram(
    "chat_duration_seconds",
    "Chat request duration"
)

# ä½¿ç”¨
@chat_duration.time()
async def chat_endpoint():
    # å¤„ç†é€»è¾‘
    pass

source_created_counter.inc()
```

---

## 12. æ€»ç»“ä¸å±•æœ›

### 12.1 æ¶æ„ä¼˜åŠ¿

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æŠ€æœ¯é€‰å‹** | ç°ä»£æŠ€æœ¯æ ˆï¼Œå¼‚æ­¥ä¼˜å…ˆï¼Œç±»å‹å®‰å…¨ |
| **å¯æ‰©å±•æ€§** | æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ°´å¹³/å‚ç›´æ‰©å±• |
| **å¼€å‘æ•ˆç‡** | è‡ªåŠ¨è¿ç§»ï¼ŒLangGraph å¯è§†åŒ–ï¼Œç±»å‹æç¤º |
| **ç”¨æˆ·ä½“éªŒ** | å¿«é€Ÿå“åº”ï¼Œå¼‚æ­¥ä»»åŠ¡ï¼ŒçŠ¶æ€è¿½è¸ª |
| **æ•°æ®å®‰å…¨** | éšç§ä¼˜å…ˆï¼Œè‡ªæ‰˜ç®¡é€‰é¡¹ |
| **AI é›†æˆ** | å¤šæä¾›å•†ï¼Œæ™ºèƒ½é€‰æ‹©ï¼Œæ— é”å®š |

### 12.2 æ½œåœ¨æ”¹è¿›

| é¢†åŸŸ | æ”¹è¿›ç‚¹ |
|------|--------|
| **è®¤è¯** | å®ç°å®Œæ•´çš„ OAuth/JWT |
| **é™æµ** | æ·»åŠ  API é€Ÿç‡é™åˆ¶ |
| **ç¼“å­˜** | å¼•å…¥ Redis ç¼“å­˜å±‚ |
| **æµ‹è¯•** | å¢åŠ é›†æˆæµ‹è¯•è¦†ç›–ç‡ |
| **æ–‡æ¡£** | å®Œå–„ API æ–‡æ¡£å’Œæ¶æ„æ–‡æ¡£ |
| **ç›‘æ§** | æ·»åŠ  Prometheus + Grafana |
| **å›½é™…åŒ–** | æ”¯æŒå¤šè¯­è¨€ç•Œé¢ |
| **ç¦»çº¿æ¨¡å¼** | æ”¯æŒæœ¬åœ° LLM å®Œå…¨ç¦»çº¿è¿è¡Œ |

### 12.3 ç¤¾åŒºä¸ç”Ÿæ€

- **å¼€æºè®¸å¯**ï¼šMIT License
- **ç¤¾åŒºæ”¯æŒ**ï¼šDiscord æœåŠ¡å™¨
- **è´¡çŒ®æŒ‡å—**ï¼šCONTRIBUTING.md
- **æ–‡æ¡£å®Œå–„**ï¼šå®Œæ•´çš„ç”¨æˆ·å’Œå¼€å‘æ–‡æ¡£

---

## é™„å½•

### A. æœ¯è¯­è¡¨

| æœ¯è¯­ | å®šä¹‰ |
|------|------|
| **SurrealDB** | å¤šæ¨¡å‹æ•°æ®åº“ï¼ˆå›¾+æ–‡æ¡£+å‘é‡ï¼‰ |
| **LangGraph** | LangChain çš„çŠ¶æ€æœºåº“ |
| **Esperanto** | å¤š AI æä¾›å•†ç»Ÿä¸€æ¥å£åº“ |
| **Vector Embedding** | æ–‡æœ¬çš„å‘é‡è¡¨ç¤ºï¼Œç”¨äºè¯­ä¹‰æœç´¢ |
| **Checkpoint** | LangGraph çŠ¶æ€æŒä¹…åŒ–æœºåˆ¶ |
| **SurrealQL** | SurrealDB çš„æŸ¥è¯¢è¯­è¨€ |

### B. å‚è€ƒèµ„æ–™

- **é¡¹ç›®ä¸»é¡µ**: https://github.com/lfnovo/open-notebook
- **å®˜æ–¹ç½‘ç«™**: https://www.open-notebook.ai
- **ç”¨æˆ·æ–‡æ¡£**: /docs/
- **API æ–‡æ¡£**: http://localhost:5055/docs
- **SurrealDB æ–‡æ¡£**: https://surrealdb.com/docs
- **LangGraph æ–‡æ¡£**: https://langchain-ai.github.io/langgraph/

### C. ç‰ˆæœ¬å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | ä¸»è¦å˜æ›´ |
|------|------|----------|
| 1.0.0 | 2024-01 | åˆå§‹ç‰ˆæœ¬ |
| 1.1.0 | 2024-06 | æ·»åŠ æ’­å®¢ç”Ÿæˆ |
| 1.2.0 | 2024-09 | å¤šæä¾›å•†æ”¯æŒ |
| 1.2.4 | 2025-01 | æ€§èƒ½ä¼˜åŒ–å’Œ bug ä¿®å¤ |

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-01-10
**ä½œè€…**: æ¶æ„åˆ†æå›¢é˜Ÿ
